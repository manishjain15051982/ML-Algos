{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'png' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"E:\\Machine Learning\\Competitions - Kaggle\\House Prices Advanced Regression Techniques/train.csv\")\n",
    "test = pd.read_csv(\"E:\\Machine Learning\\Competitions - Kaggle\\House Prices Advanced Regression Techniques/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      test.loc[:,'MSSubClass':'SaleCondition']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filling NA's with the mean of the column:\n",
    "all_data = all_data.fillna(all_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = all_data[:train.shape[0]]\n",
    "X_test = all_data[train.shape[0]:]\n",
    "y = train.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manish_jain04.ITLINFOSYS\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "y=y.reshape(1460,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (1460, 288) (1460, 1)\n",
      "Test set (1459, 288)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', X_train.shape, y.shape)\n",
    "print('Test set',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train.T\n",
    "X_test=X_test.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (288, 1460) (1, 1460)\n",
      "Test set (288, 1459)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', X_train.shape, y.shape)\n",
    "print('Test set',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train.astype(np.float32)\n",
    "X_test=X_test.astype(np.float32)\n",
    "y =y.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (288, 1460) (1, 1460)\n",
      "Test set (288, 1459)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', X_train.shape, y.shape)\n",
    "print('Test set',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (288, 1460) (1, 1460)\n"
     ]
    }
   ],
   "source": [
    "def reformat(dataset, labels):\n",
    "  \n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  labels = (np.arange(1) == labels[:,:]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(X_train, y)\n",
    "                                     \n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    X = tf.placeholder(tf.float32,shape=(n_x,None))\n",
    "    Y = tf.placeholder(tf.float32,shape=(n_y,None))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [1, 12]\n",
    "                        b3 : [1, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [25,288], initializer = tf.contrib.layers.xavier_initializer(seed = 1),dtype=tf.float32)\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer(),dtype=tf.float32)\n",
    "    W2 = tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1),dtype=tf.float32)\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer(),dtype=tf.float32)\n",
    "    W3 = tf.get_variable(\"W3\", [1,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1),dtype=tf.float32)\n",
    "    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer(),dtype=tf.float32)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    A3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                          # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                              # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                              # Z3 = np.dot(W3,Z2) + b3\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(A3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    A3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    #logits = tf.transpose(A3)\n",
    "    #labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.square(tf.squeeze(A3)-tf.squeeze(Y)))\n",
    "                  \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, learning_rate = 0.0001,\n",
    "          num_epochs = 501, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    A3 = forward_propagation(X,parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(A3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            #epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            #num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            #seed = seed + 1\n",
    "            #minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            #for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "             #   (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "            _ , epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "            #epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(A3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        #print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 454.743652\n",
      "Cost after epoch 100: 0.036959\n",
      "Cost after epoch 200: 0.005057\n",
      "Cost after epoch 300: 0.000816\n",
      "Cost after epoch 400: 0.000085\n",
      "Cost after epoch 500: 0.000006\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAETCAYAAADUAmpRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13e234749e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "parameters = model(train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
